{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## IoT for Eco-Friendly Tourism - Summer School\n",
    "### Valencia, Spain - 2025\n",
    "\n",
    "------- -->\n",
    "\n",
    "![alt text](remarkable.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-Level Synthesis for Machine Learning (hls4ml)\n",
    "\n",
    "\n",
    "ðŸ’¡ **High-Level Synthesis for Machine Learning (hls4ml)**  is an open-source library that transforms machine learning models into hardware descriptions optimized for FPGA deployment.\n",
    "\n",
    "**Key Features of hls4ml:** \n",
    "\n",
    "- Converts models from Keras, TensorFlow, PyTorch, and ONNX into High-Level Synthesis (HLS) projects.\n",
    "\n",
    "- Utilizes tools like Xilinx Vitis HLS and Intel HLS Compiler to generate optimized C++ code for hardware implementation.\n",
    "\n",
    "- Enhances efficiency by reducing latency and power consumption, making it ideal for AI applications in edge computing.\n",
    "\n",
    "- Supports quantization and pruning techniques to shrink model size while maintaining accuracy.\n",
    "\n",
    "\n",
    "For further details:\n",
    "\n",
    "- GitHub: https://github.com/fastmachinelearning/hls4ml\n",
    "\n",
    "- Web site: https://fastmachinelearning.org/hls4ml/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LibrerÃ­as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 11:00:19.934952: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/tools/anaconda3/envs/neuralEnv/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: Unable to import optimizer(s) from expr_templates.py: No module named 'sympy'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from qkeras import *\n",
    "from qkeras import QActivation\n",
    "from qkeras import QDense, QConv2DBatchnorm\n",
    "import hls4ml\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path a Vitis HLS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como paso inicial se debe especificar el directorio de instalaciÃ³n de Vivado HLS o Vitis HLS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tools/Xilinx/XilinxUnified_2022/Vitis_HLS/2022.2/bin:/tools/anaconda3/envs/neuralEnv/bin:/tools/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['PATH'] = '/tools/Xilinx/XilinxUnified_2022/Vitis_HLS/2022.2/bin:' + os.environ['PATH']\n",
    "# os.environ['PATH'] = '/tools/Xilinx2019/Vivado/2019.2/bin:' + os.environ['PATH']\n",
    "os.environ['PATH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the model (.h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 11:00:22.895980: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2025-03-25 11:00:22.896918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2025-03-25 11:00:23.566746: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-03-25 11:00:23.566792: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mareKaleido\n",
      "2025-03-25 11:00:23.566799: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mareKaleido\n",
      "2025-03-25 11:00:23.567013: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 535.183.1\n",
      "2025-03-25 11:00:23.567058: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 535.183.1\n",
      "2025-03-25 11:00:23.567068: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 535.183.1\n",
      "2025-03-25 11:00:23.569200: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-25 11:00:23.570109: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "fc1_input (QDense)           (None, 5)                 3925      \n",
      "_________________________________________________________________\n",
      "relu_input (QActivation)     (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "fc1 (QDense)                 (None, 7)                 42        \n",
      "_________________________________________________________________\n",
      "relu1 (QActivation)          (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "fc2 (QDense)                 (None, 10)                80        \n",
      "_________________________________________________________________\n",
      "relu2 (QActivation)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "output (QDense)              (None, 2)                 22        \n",
      "_________________________________________________________________\n",
      "sigmoid (Activation)         (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 4,069\n",
      "Trainable params: 4,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "co = {}\n",
    "_add_supported_quantized_objects(co)\n",
    "model = load_model('models/mnistPQKD.h5', custom_objects=co)\n",
    "    \n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Weight distribution\n",
    "\n",
    "weights = np.concatenate([w.flatten() for w in model.get_weights()])\n",
    "\n",
    "plt.figure(figsize=(10,2))\n",
    "plt.hist(weights, bins=60, color='green', alpha=0.6)\n",
    "plt.xlabel(\"Weight Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Model MLP for MNIST - Weight Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### high-Level Synthesis for Machine Learning (hls4ml )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hls configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input_input, layer type: InputLayer, input shapes: [[None, 784]], output shape: [None, 784]\n",
      "Layer name: fc1_input, layer type: QDense, input shapes: [[None, 784]], output shape: [None, 5]\n",
      "Layer name: relu_input, layer type: Activation, input shapes: [[None, 5]], output shape: [None, 5]\n",
      "Layer name: fc1, layer type: QDense, input shapes: [[None, 5]], output shape: [None, 7]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 7]], output shape: [None, 7]\n",
      "Layer name: fc2, layer type: QDense, input shapes: [[None, 7]], output shape: [None, 10]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 10]], output shape: [None, 10]\n",
      "Layer name: output, layer type: QDense, input shapes: [[None, 10]], output shape: [None, 2]\n",
      "Layer name: sigmoid, layer type: Activation, input shapes: [[None, 2]], output shape: [None, 2]\n",
      "-----------------------------------\n",
      "Model\n",
      "  Precision:         fixed<16,6>\n",
      "  ReuseFactor:       1\n",
      "  Strategy:          Latency\n",
      "  BramFactor:        1000000000\n",
      "  TraceOutput:       False\n",
      "LayerName\n",
      "  fc1_input_input\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "  fc1_input\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "      weight:        fixed<8,4>\n",
      "      bias:          fixed<8,4>\n",
      "  fc1_input_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "  relu_input\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,7,RND_CONV,SAT>\n",
      "  fc1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "      weight:        fixed<8,4>\n",
      "      bias:          fixed<8,4>\n",
      "  fc1_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "  relu1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,7,RND_CONV,SAT>\n",
      "  fc2\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "      weight:        fixed<8,4>\n",
      "      bias:          fixed<8,4>\n",
      "  fc2_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "  relu2\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,7,RND_CONV,SAT>\n",
      "  output\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "      weight:        fixed<8,4>\n",
      "      bias:          fixed<8,4>\n",
      "  output_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "  sigmoid\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "hls4ml.model.optimizer.get_optimizer('output_rounding_saturation_mode').configure(layers=['Activation'])\n",
    "hls4ml.model.optimizer.get_optimizer('output_rounding_saturation_mode').configure(rounding_mode='AP_RND')\n",
    "hls4ml.model.optimizer.get_optimizer('output_rounding_saturation_mode').configure(saturation_mode='AP_SAT')\n",
    "\n",
    "\n",
    "hls_config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "import plotting\n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "plotting.print_dict(hls_config)\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in hls_config['LayerName'].keys():\n",
    "    hls_config['LayerName'][layer]['Trace'] = True\n",
    "    hls_config['LayerName'][layer]['ReuseFactor'] = 16\n",
    "\n",
    "hls_config['LayerName']['fc1_input_input']['Precision'] = 'ap_fixed<16, 6>'   \n",
    "hls_config['LayerName']['sigmoid']['Strategy'] = 'Stable'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hls4ml with Vitis HLS as backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input_input, layer type: InputLayer, input shapes: [[None, 784]], output shape: [None, 784]\n",
      "Layer name: fc1_input, layer type: QDense, input shapes: [[None, 784]], output shape: [None, 5]\n",
      "Layer name: relu_input, layer type: Activation, input shapes: [[None, 5]], output shape: [None, 5]\n",
      "Layer name: fc1, layer type: QDense, input shapes: [[None, 5]], output shape: [None, 7]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 7]], output shape: [None, 7]\n",
      "Layer name: fc2, layer type: QDense, input shapes: [[None, 7]], output shape: [None, 10]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 10]], output shape: [None, 10]\n",
      "Layer name: output, layer type: QDense, input shapes: [[None, 10]], output shape: [None, 2]\n",
      "Layer name: sigmoid, layer type: Activation, input shapes: [[None, 2]], output shape: [None, 2]\n",
      "Creating HLS model\n"
     ]
    }
   ],
   "source": [
    "cfg = hls4ml.converters.create_config(backend='vitis')\n",
    "\n",
    "# cfg['IOType']     = 'io_stream'   # Must set this if using CNNs!\n",
    "cfg['HLSConfig']  = hls_config      # HLS configuraiton\n",
    "cfg['KerasModel'] = model           # Keras model to be converted\n",
    "cfg['OutputDir']  = 'hls4ml/'       # Project name\n",
    "cfg['Part'] = 'xc7z020clg484-1'     # PYNQ-Z1 or Zedboard: xc7z020clg484-1  ARTIX-7 xc7a35tcsg325-1  # MPSoC xczu4eg-sfvc784-2-e  xczu3eg-sfvc784-1-e\n",
    "\n",
    "\n",
    "hls_model = hls4ml.converters.keras_to_hls(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing HLS project\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hardware synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2022.2 (64-bit)\n",
      "  **** SW Build 3670227 on Oct 13 2022\n",
      "  **** IP Build 3669848 on Fri Oct 14 08:30:02 MDT 2022\n",
      "    ** Copyright 1986-2022 Xilinx, Inc. All Rights Reserved.\n",
      "\n",
      "source /tools/Xilinx/XilinxUnified_2022/Vitis_HLS/2022.2/scripts/vitis_hls/hls.tcl -notrace\n",
      "INFO: [HLS 200-10] Running '/tools/Xilinx/XilinxUnified_2022/Vitis_HLS/2022.2/bin/unwrapped/lnx64.o/vitis_hls'\n",
      "INFO: [HLS 200-10] For user 'ro' on host 'mareKaleido' (Linux_x86_64 version 5.15.0-134-generic) on Tue Mar 25 11:00:32 CET 2025\n",
      "INFO: [HLS 200-10] On os Ubuntu 20.04.6 LTS\n",
      "INFO: [HLS 200-10] In directory '/media/ro/Data/workspace/hls4ml/Valencia2025/v2022_3'\n",
      "Sourcing Tcl script 'build_prj.tcl'\n",
      "INFO: [HLS 200-1510] Running: open_project myproject_prj \n",
      "INFO: [HLS 200-10] Creating and opening project '/media/ro/Data/workspace/hls4ml/Valencia2025/v2022_3/myproject_prj'.\n",
      "INFO: [HLS 200-1510] Running: set_top myproject \n",
      "INFO: [HLS 200-1510] Running: add_files firmware/myproject.cpp -cflags -std=c++0x \n",
      "INFO: [HLS 200-10] Adding design file 'firmware/myproject.cpp' to the project\n",
      "INFO: [HLS 200-1510] Running: add_files -tb myproject_test.cpp -cflags -std=c++0x \n",
      "INFO: [HLS 200-10] Adding test bench file 'myproject_test.cpp' to the project\n",
      "INFO: [HLS 200-1510] Running: add_files -tb firmware/weights \n",
      "INFO: [HLS 200-10] Adding test bench file 'firmware/weights' to the project\n",
      "INFO: [HLS 200-1510] Running: add_files -tb tb_data \n",
      "INFO: [HLS 200-10] Adding test bench file 'tb_data' to the project\n",
      "INFO: [HLS 200-1510] Running: open_solution solution1 \n",
      "INFO: [HLS 200-10] Creating and opening solution '/media/ro/Data/workspace/hls4ml/Valencia2025/v2022_3/myproject_prj/solution1'.\n",
      "INFO: [HLS 200-1505] Using default flow_target 'vivado'\n",
      "Resolution: For help on HLS 200-1505 see www.xilinx.com/cgi-bin/docs/rdoc?v=2022.2;t=hls+guidance;d=200-1505.html\n",
      "INFO: [HLS 200-435] Setting 'open_solution -flow_target vivado' configuration: config_interface -m_axi_latency=0\n",
      "INFO: [HLS 200-1510] Running: config_array_partition -maximum_size 4096 \n",
      "INFO: [XFORM 203-101] Allowed max sub elements number after partition is 4096.\n",
      "ERROR: [HLS 200-642] The 'config_array_partition -maximum_size' command is not supported.\n",
      "INFO: [HLS 200-1510] Running: config_compile -name_max_length 80 \n",
      "INFO: [XFORM 203-1161] The maximum of name length is set to 80.\n",
      "INFO: [HLS 200-1510] Running: set_part xc7z020clg484-1 \n",
      "INFO: [HLS 200-1611] Setting target device to 'xc7z020-clg484-1'\n",
      "INFO: [XFORM 203-1161] The maximum of name length is set to 80.\n",
      "INFO: [HLS 200-1510] Running: config_schedule -enable_dsp_full_reg=false \n",
      "INFO: [HLS 200-1510] Running: create_clock -period 5 -name default \n",
      "INFO: [SYN 201-201] Setting up clock 'default' with a period of 5ns.\n",
      "INFO: [HLS 200-1510] Running: set_clock_uncertainty 12.5% default \n",
      "INFO: [SYN 201-201] Setting up clock 'default' with an uncertainty of 0.625ns.\n",
      "***** C/RTL SYNTHESIS *****\n",
      "INFO: [HLS 200-1510] Running: csynth_design \n",
      "Running Dispatch Server on port: 40979\n",
      "INFO: [HLS 200-111] Finished File checks and directory preparation: CPU user time: 0.03 seconds. CPU system time: 0.01 seconds. Elapsed time: 10.05 seconds; current allocated memory: 259.488 MB.\n",
      "INFO: [HLS 200-10] Analyzing design file 'firmware/myproject.cpp' ... \n",
      "WARNING: [HLS 207-5292] unused parameter 'keep' (firmware/nnet_utils/nnet_helpers.h:285:99)\n",
      "WARNING: [HLS 207-5292] unused parameter 'data' (firmware/nnet_utils/nnet_code_gen.h:11:36)\n",
      "WARNING: [HLS 207-5292] unused parameter 'buffer' (firmware/nnet_utils/nnet_code_gen.h:12:36)\n",
      "WARNING: [HLS 207-5292] unused parameter 'partition' (firmware/nnet_utils/nnet_code_gen.h:13:44)\n",
      "WARNING: [HLS 207-5292] unused parameter 'data' (firmware/nnet_utils/nnet_code_gen.h:21:24)\n",
      "WARNING: [HLS 207-5292] unused parameter 'buffer' (firmware/nnet_utils/nnet_code_gen.h:22:24)\n",
      "WARNING: [HLS 207-5292] unused parameter 'partition' (firmware/nnet_utils/nnet_code_gen.h:23:32)\n",
      "INFO: [HLS 200-111] Finished Source Code Analysis and Preprocessing: CPU user time: 8.04 seconds. CPU system time: 0.52 seconds. Elapsed time: 8.64 seconds; current allocated memory: 264.648 MB.\n",
      "INFO: [HLS 200-777] Using interface defaults for 'Vivado' flow target.\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<8, 4, (ap_q_mode)5, (ap_o_mode)3, 0> >::product(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<8, 4, (ap_q_mode)5, (ap_o_mode)3, 0>)' into 'void nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config2::weight_t*, config2::bias_t*)' (firmware/nnet_utils/nnet_dense_latency.h:42:27)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::product::mult<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<8, 4, (ap_q_mode)5, (ap_o_mode)3, 0> >::product(ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<8, 4, (ap_q_mode)5, (ap_o_mode)3, 0>)' into 'void nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>(ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config5::weight_t*, config5::bias_t*)' (firmware/nnet_utils/nnet_dense_latency.h:42:27)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::product::mult<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<8, 4, (ap_q_mode)5, (ap_o_mode)3, 0> >::product(ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<8, 4, (ap_q_mode)5, (ap_o_mode)3, 0>)' into 'void nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>(ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config8::weight_t*, config8::bias_t*)' (firmware/nnet_utils/nnet_dense_latency.h:42:27)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::product::mult<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<8, 4, (ap_q_mode)5, (ap_o_mode)3, 0> >::product(ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<8, 4, (ap_q_mode)5, (ap_o_mode)3, 0>)' into 'void nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>(ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config11::weight_t*, config11::bias_t*)' (firmware/nnet_utils/nnet_dense_latency.h:42:27)\n",
      "INFO: [HLS 214-131] Inlining function 'void nnet::dense<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config2::weight_t*, config2::bias_t*)' into 'myproject(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>*)' (firmware/myproject.cpp:41:2)\n",
      "INFO: [HLS 214-131] Inlining function 'void nnet::dense<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>(ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config5::weight_t*, config5::bias_t*)' into 'myproject(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>*)' (firmware/myproject.cpp:53:2)\n",
      "INFO: [HLS 214-131] Inlining function 'void nnet::dense<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>(ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config8::weight_t*, config8::bias_t*)' into 'myproject(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>*)' (firmware/myproject.cpp:65:2)\n",
      "INFO: [HLS 214-131] Inlining function 'void nnet::dense<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>(ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config11::weight_t*, config11::bias_t*)' into 'myproject(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>*)' (firmware/myproject.cpp:77:2)\n",
      "INFO: [HLS 214-291] Loop 'anonymous' is marked as complete unroll implied by the pipeline pragma (firmware/myproject.cpp:79:15)\n",
      "INFO: [HLS 214-291] Loop 'anonymous' is marked as complete unroll implied by the pipeline pragma (firmware/myproject.cpp:75:15)\n",
      "INFO: [HLS 214-291] Loop 'anonymous' is marked as complete unroll implied by the pipeline pragma (firmware/myproject.cpp:71:15)\n",
      "INFO: [HLS 214-291] Loop 'anonymous' is marked as complete unroll implied by the pipeline pragma (firmware/myproject.cpp:67:14)\n",
      "INFO: [HLS 214-291] Loop 'anonymous' is marked as complete unroll implied by the pipeline pragma (firmware/myproject.cpp:63:14)\n",
      "INFO: [HLS 214-291] Loop 'anonymous' is marked as complete unroll implied by the pipeline pragma (firmware/myproject.cpp:59:14)\n",
      "INFO: [HLS 214-291] Loop 'anonymous' is marked as complete unroll implied by the pipeline pragma (firmware/myproject.cpp:55:14)\n",
      "INFO: [HLS 214-291] Loop 'anonymous' is marked as complete unroll implied by the pipeline pragma (firmware/myproject.cpp:51:14)\n",
      "INFO: [HLS 214-291] Loop 'anonymous' is marked as complete unroll implied by the pipeline pragma (firmware/myproject.cpp:47:14)\n",
      "INFO: [HLS 214-291] Loop 'anonymous' is marked as complete unroll implied by the pipeline pragma (firmware/myproject.cpp:43:14)\n",
      "INFO: [HLS 214-291] Loop 'anonymous' is marked as complete unroll implied by the pipeline pragma (firmware/myproject.cpp:39:11)\n",
      "INFO: [HLS 214-291] Loop 'VITIS_LOOP_114_1' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_activation.h:114:23)\n",
      "INFO: [HLS 214-291] Loop 'anonymous' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_activation.h:99:32)\n",
      "INFO: [HLS 214-291] Loop 'VITIS_LOOP_31_1' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_activation.h:31:19)\n",
      "INFO: [HLS 214-291] Loop 'Result' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_dense_latency.h:64:5)\n",
      "INFO: [HLS 214-291] Loop 'Accum1' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_dense_latency.h:54:5)\n",
      "INFO: [HLS 214-291] Loop 'Accum2' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_dense_latency.h:56:9)\n",
      "INFO: [HLS 214-291] Loop 'ResetAccum' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_dense_latency.h:48:5)\n",
      "INFO: [HLS 214-291] Loop 'Product1' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_dense_latency.h:37:5)\n",
      "INFO: [HLS 214-291] Loop 'Product2' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_dense_latency.h:40:9)\n",
      "INFO: [HLS 214-291] Loop 'anonymous' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_dense_latency.h:18:32)\n",
      "INFO: [HLS 214-291] Loop 'anonymous' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_dense_latency.h:17:32)\n",
      "INFO: [HLS 214-186] Unrolling loop 'anonymous' (firmware/myproject.cpp:79:15) in function 'myproject' completely with a factor of 2 (firmware/myproject.cpp:9:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'anonymous' (firmware/myproject.cpp:75:15) in function 'myproject' completely with a factor of 2 (firmware/myproject.cpp:9:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'anonymous' (firmware/myproject.cpp:71:15) in function 'myproject' completely with a factor of 10 (firmware/myproject.cpp:9:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'anonymous' (firmware/myproject.cpp:67:14) in function 'myproject' completely with a factor of 10 (firmware/myproject.cpp:9:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'anonymous' (firmware/myproject.cpp:63:14) in function 'myproject' completely with a factor of 10 (firmware/myproject.cpp:9:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'anonymous' (firmware/myproject.cpp:59:14) in function 'myproject' completely with a factor of 7 (firmware/myproject.cpp:9:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'anonymous' (firmware/myproject.cpp:55:14) in function 'myproject' completely with a factor of 7 (firmware/myproject.cpp:9:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'anonymous' (firmware/myproject.cpp:51:14) in function 'myproject' completely with a factor of 7 (firmware/myproject.cpp:9:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'anonymous' (firmware/myproject.cpp:47:14) in function 'myproject' completely with a factor of 5 (firmware/myproject.cpp:9:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'anonymous' (firmware/myproject.cpp:43:14) in function 'myproject' completely with a factor of 5 (firmware/myproject.cpp:9:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'anonymous' (firmware/myproject.cpp:39:11) in function 'myproject' completely with a factor of 5 (firmware/myproject.cpp:9:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'VITIS_LOOP_114_1' (firmware/nnet_utils/nnet_activation.h:114:23) in function 'nnet::sigmoid<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, sigmoid_config13>' completely with a factor of 2 (firmware/nnet_utils/nnet_activation.h:95:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'anonymous' (firmware/nnet_utils/nnet_activation.h:99:32) in function 'nnet::sigmoid<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, sigmoid_config13>' completely with a factor of 1024 (firmware/nnet_utils/nnet_activation.h:95:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'VITIS_LOOP_31_1' (firmware/nnet_utils/nnet_activation.h:31:19) in function 'nnet::linear<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, linear_config12>' completely with a factor of 2 (firmware/nnet_utils/nnet_activation.h:28:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_latency.h:64:5) in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' completely with a factor of 2 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Accum1' (firmware/nnet_utils/nnet_dense_latency.h:54:5) in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' completely with a factor of 10 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Accum2' (firmware/nnet_utils/nnet_dense_latency.h:56:9) in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' completely with a factor of 2 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'ResetAccum' (firmware/nnet_utils/nnet_dense_latency.h:48:5) in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' completely with a factor of 2 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Product1' (firmware/nnet_utils/nnet_dense_latency.h:37:5) in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' completely with a factor of 10 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Product2' (firmware/nnet_utils/nnet_dense_latency.h:40:9) in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' completely with a factor of 2 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'anonymous' (firmware/nnet_utils/nnet_dense_latency.h:18:32) in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' completely with a factor of 2 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'anonymous' (firmware/nnet_utils/nnet_dense_latency.h:17:32) in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' completely with a factor of 20 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'VITIS_LOOP_31_1' (firmware/nnet_utils/nnet_activation.h:31:19) in function 'nnet::linear<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, linear_config10>' completely with a factor of 10 (firmware/nnet_utils/nnet_activation.h:28:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'VITIS_LOOP_31_1' (firmware/nnet_utils/nnet_activation.h:31:19) in function 'nnet::linear<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, linear_config9>' completely with a factor of 10 (firmware/nnet_utils/nnet_activation.h:28:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_latency.h:64:5) in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' completely with a factor of 10 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Accum1' (firmware/nnet_utils/nnet_dense_latency.h:54:5) in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' completely with a factor of 7 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Accum2' (firmware/nnet_utils/nnet_dense_latency.h:56:9) in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' completely with a factor of 10 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'ResetAccum' (firmware/nnet_utils/nnet_dense_latency.h:48:5) in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' completely with a factor of 10 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Product1' (firmware/nnet_utils/nnet_dense_latency.h:37:5) in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' completely with a factor of 7 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Product2' (firmware/nnet_utils/nnet_dense_latency.h:40:9) in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' completely with a factor of 10 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'anonymous' (firmware/nnet_utils/nnet_dense_latency.h:18:32) in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' completely with a factor of 10 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'anonymous' (firmware/nnet_utils/nnet_dense_latency.h:17:32) in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' completely with a factor of 70 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'VITIS_LOOP_31_1' (firmware/nnet_utils/nnet_activation.h:31:19) in function 'nnet::linear<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, linear_config7>' completely with a factor of 7 (firmware/nnet_utils/nnet_activation.h:28:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'VITIS_LOOP_31_1' (firmware/nnet_utils/nnet_activation.h:31:19) in function 'nnet::linear<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, linear_config6>' completely with a factor of 7 (firmware/nnet_utils/nnet_activation.h:28:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_latency.h:64:5) in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' completely with a factor of 7 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Accum1' (firmware/nnet_utils/nnet_dense_latency.h:54:5) in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' completely with a factor of 5 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Accum2' (firmware/nnet_utils/nnet_dense_latency.h:56:9) in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' completely with a factor of 7 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'ResetAccum' (firmware/nnet_utils/nnet_dense_latency.h:48:5) in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' completely with a factor of 7 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Product1' (firmware/nnet_utils/nnet_dense_latency.h:37:5) in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' completely with a factor of 5 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Product2' (firmware/nnet_utils/nnet_dense_latency.h:40:9) in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' completely with a factor of 7 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'anonymous' (firmware/nnet_utils/nnet_dense_latency.h:18:32) in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' completely with a factor of 7 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'anonymous' (firmware/nnet_utils/nnet_dense_latency.h:17:32) in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' completely with a factor of 35 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'VITIS_LOOP_31_1' (firmware/nnet_utils/nnet_activation.h:31:19) in function 'nnet::linear<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, linear_config4>' completely with a factor of 5 (firmware/nnet_utils/nnet_activation.h:28:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'VITIS_LOOP_31_1' (firmware/nnet_utils/nnet_activation.h:31:19) in function 'nnet::linear<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, linear_config3>' completely with a factor of 5 (firmware/nnet_utils/nnet_activation.h:28:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_latency.h:64:5) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 5 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Accum1' (firmware/nnet_utils/nnet_dense_latency.h:54:5) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 784 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Accum2' (firmware/nnet_utils/nnet_dense_latency.h:56:9) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 5 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'ResetAccum' (firmware/nnet_utils/nnet_dense_latency.h:48:5) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 5 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Product1' (firmware/nnet_utils/nnet_dense_latency.h:37:5) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 784 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Product2' (firmware/nnet_utils/nnet_dense_latency.h:40:9) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 5 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'anonymous' (firmware/nnet_utils/nnet_dense_latency.h:18:32) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 5 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'anonymous' (firmware/nnet_utils/nnet_dense_latency.h:17:32) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 3920 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-178] Inlining function 'std::enable_if<!(std::is_same<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_uint<1> >::value), ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::type nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>(config2::accum_t)' into 'void nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config2::weight_t*, config2::bias_t*)' (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-178] Inlining function 'std::enable_if<!(std::is_same<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_uint<1> >::value), ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::type nnet::cast<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>(config5::accum_t)' into 'void nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>(ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config5::weight_t*, config5::bias_t*)' (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-178] Inlining function 'std::enable_if<!(std::is_same<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_uint<1> >::value), ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::type nnet::cast<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>(config8::accum_t)' into 'void nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>(ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config8::weight_t*, config8::bias_t*)' (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-178] Inlining function 'std::enable_if<!(std::is_same<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_uint<1> >::value), ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::type nnet::cast<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>(config11::accum_t)' into 'void nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>(ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config11::weight_t*, config11::bias_t*)' (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'b11': Complete partitioning on dimension 1. (firmware/weights/b11.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'b8': Complete partitioning on dimension 1. (firmware/weights/b8.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'b5': Complete partitioning on dimension 1. (firmware/weights/b5.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'b2': Complete partitioning on dimension 1. (firmware/weights/b2.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'mult': Complete partitioning on dimension 1. (firmware/nnet_utils/nnet_dense_latency.h:17:32)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer2_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:39:11)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer3_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:43:14)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer4_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:47:14)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer5_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:51:14)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer6_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:55:14)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer7_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:59:14)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer8_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:63:14)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer9_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:67:14)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer10_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:71:15)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer11_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:75:15)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer12_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:79:15)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer13_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:9:0)\n",
      "WARNING: [HLS 214-292] Unsupported reshape pragma/directive on variable 'fc1_input_input'. The port size might be shrunk or fail cosim as the bit-width after reshape (12544) is larger than 4096\n",
      "INFO: [HLS 214-248] Applying array_reshape to 'fc1_input_input': Complete reshaping on dimension 1. (firmware/myproject.cpp:9:0)\n",
      "INFO: [HLS 200-111] Finished Compiling Optimization and Transform: CPU user time: 314.44 seconds. CPU system time: 1.12 seconds. Elapsed time: 315.91 seconds; current allocated memory: 285.469 MB.\n",
      "INFO: [HLS 200-111] Finished Checking Pragmas: CPU user time: 0.01 seconds. CPU system time: 0 seconds. Elapsed time: 0 seconds; current allocated memory: 285.469 MB.\n",
      "INFO: [HLS 200-10] Starting code transformations ...\n",
      "INFO: [HLS 200-111] Finished Standard Transforms: CPU user time: 0.75 seconds. CPU system time: 0.06 seconds. Elapsed time: 0.81 seconds; current allocated memory: 419.258 MB.\n",
      "INFO: [HLS 200-10] Checking synthesizability ...\n",
      "INFO: [HLS 200-111] Finished Checking Synthesizability: CPU user time: 0.89 seconds. CPU system time: 0.03 seconds. Elapsed time: 0.93 seconds; current allocated memory: 504.199 MB.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/nnet_utils/nnet_activation.h:109:9) to (firmware/nnet_utils/nnet_activation.h:123:1) in function 'nnet::sigmoid<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, sigmoid_config13>'... converting 5 basic blocks.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' (firmware/nnet_utils/nnet_dense_latency.h:33:1)...46 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' (firmware/nnet_utils/nnet_dense_latency.h:33:1)...18 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::dense_latency<ap_fixed<16, 7, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' (firmware/nnet_utils/nnet_dense_latency.h:33:1)...14 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' (firmware/nnet_utils/nnet_dense_latency.h:33:1)...1893 expression(s) balanced.\n",
      "INFO: [HLS 200-111] Finished Loop, function and other optimizations: CPU user time: 1.8 seconds. CPU system time: 0.05 seconds. Elapsed time: 1.87 seconds; current allocated memory: 670.312 MB.\n",
      "INFO: [HLS 200-111] Finished Architecture Synthesis: CPU user time: 2.5 seconds. CPU system time: 0.04 seconds. Elapsed time: 2.54 seconds; current allocated memory: 870.746 MB.\n",
      "INFO: [HLS 200-10] Starting hardware synthesis ...\n",
      "INFO: [HLS 200-10] Synthesizing 'myproject' ...\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_latency<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config2>' to 'dense_latency_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config2_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'linear<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 0, 0, 0>, linear_config3>' to 'linear_ap_fixed_16_6_5_3_0_ap_fixed_16_6_0_0_0_linear_config3_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'linear<ap_fixed<16, 6, 0, 0, 0>, ap_fixed<16, 7, 0, 0, 0>, linear_config4>' to 'linear_ap_fixed_16_6_0_0_0_ap_fixed_16_7_0_0_0_linear_config4_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_latency<ap_fixed<16, 7, 0, 0, 0>, ap_fixed<16, 6, 5, 3, 0>, config5>' to 'dense_latency_ap_fixed_16_7_0_0_0_ap_fixed_16_6_5_3_0_config5_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'linear<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 0, 0, 0>, linear_config6>' to 'linear_ap_fixed_16_6_5_3_0_ap_fixed_16_6_0_0_0_linear_config6_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'linear<ap_fixed<16, 6, 0, 0, 0>, ap_fixed<16, 7, 0, 0, 0>, linear_config7>' to 'linear_ap_fixed_16_6_0_0_0_ap_fixed_16_7_0_0_0_linear_config7_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_latency<ap_fixed<16, 7, 0, 0, 0>, ap_fixed<16, 6, 5, 3, 0>, config8>' to 'dense_latency_ap_fixed_16_7_0_0_0_ap_fixed_16_6_5_3_0_config8_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'linear<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 0, 0, 0>, linear_config9>' to 'linear_ap_fixed_16_6_5_3_0_ap_fixed_16_6_0_0_0_linear_config9_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'linear<ap_fixed<16, 6, 0, 0, 0>, ap_fixed<16, 7, 0, 0, 0>, linear_config10>' to 'linear_ap_fixed_16_6_0_0_0_ap_fixed_16_7_0_0_0_linear_config10_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_latency<ap_fixed<16, 7, 0, 0, 0>, ap_fixed<16, 6, 5, 3, 0>, config11>' to 'dense_latency_ap_fixed_16_7_0_0_0_ap_fixed_16_6_5_3_0_config11_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'linear<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 0, 0, 0>, linear_config12>' to 'linear_ap_fixed_16_6_5_3_0_ap_fixed_16_6_0_0_0_linear_config12_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'sigmoid<ap_fixed<16, 6, 0, 0, 0>, ap_fixed<16, 6, 0, 0, 0>, sigmoid_config13>' to 'sigmoid_ap_fixed_16_6_0_0_0_ap_fixed_16_6_0_0_0_sigmoid_config13_s'.\n",
      "WARNING: [SYN 201-223] Checking resource limit in 'dense_latency<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config2>': cannot find any operation of 'mul'.\n",
      "WARNING: [SYN 201-223] Checking resource limit in 'dense_latency<ap_fixed<16, 7, 0, 0, 0>, ap_fixed<16, 6, 5, 3, 0>, config11>': cannot find any operation of 'mul'.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_latency_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'dense_latency<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config2>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 8, Depth = 8, function 'dense_latency<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config2>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 4.28 seconds. CPU system time: 0.06 seconds. Elapsed time: 4.35 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 7.67 seconds. CPU system time: 0.01 seconds. Elapsed time: 7.68 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'linear_ap_fixed_16_6_5_3_0_ap_fixed_16_6_0_0_0_linear_config3_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'linear<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 0, 0, 0>, linear_config3>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 1, function 'linear<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 0, 0, 0>, linear_config3>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 5.57 seconds. CPU system time: 0.01 seconds. Elapsed time: 5.62 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.01 seconds. CPU system time: 0 seconds. Elapsed time: 0.01 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'linear_ap_fixed_16_6_0_0_0_ap_fixed_16_7_0_0_0_linear_config4_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'linear<ap_fixed<16, 6, 0, 0, 0>, ap_fixed<16, 7, 0, 0, 0>, linear_config4>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 1, function 'linear<ap_fixed<16, 6, 0, 0, 0>, ap_fixed<16, 7, 0, 0, 0>, linear_config4>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.03 seconds. CPU system time: 0 seconds. Elapsed time: 0.03 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.02 seconds. CPU system time: 0 seconds. Elapsed time: 0.01 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_latency_ap_fixed_16_7_0_0_0_ap_fixed_16_6_5_3_0_config5_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'dense_latency<ap_fixed<16, 7, 0, 0, 0>, ap_fixed<16, 6, 5, 3, 0>, config5>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 4, Depth = 4, function 'dense_latency<ap_fixed<16, 7, 0, 0, 0>, ap_fixed<16, 6, 5, 3, 0>, config5>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.08 seconds. CPU system time: 0 seconds. Elapsed time: 0.08 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.07 seconds. CPU system time: 0 seconds. Elapsed time: 0.07 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'linear_ap_fixed_16_6_5_3_0_ap_fixed_16_6_0_0_0_linear_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'linear<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 0, 0, 0>, linear_config6>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 1, function 'linear<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 0, 0, 0>, linear_config6>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.11 seconds. CPU system time: 0 seconds. Elapsed time: 0.14 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.01 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.01 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'linear_ap_fixed_16_6_0_0_0_ap_fixed_16_7_0_0_0_linear_config7_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'linear<ap_fixed<16, 6, 0, 0, 0>, ap_fixed<16, 7, 0, 0, 0>, linear_config7>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 1, function 'linear<ap_fixed<16, 6, 0, 0, 0>, ap_fixed<16, 7, 0, 0, 0>, linear_config7>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.04 seconds. CPU system time: 0 seconds. Elapsed time: 0.03 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.02 seconds. CPU system time: 0 seconds. Elapsed time: 0.02 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_latency_ap_fixed_16_7_0_0_0_ap_fixed_16_6_5_3_0_config8_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'dense_latency<ap_fixed<16, 7, 0, 0, 0>, ap_fixed<16, 6, 5, 3, 0>, config8>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 4, Depth = 4, function 'dense_latency<ap_fixed<16, 7, 0, 0, 0>, ap_fixed<16, 6, 5, 3, 0>, config8>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.15 seconds. CPU system time: 0 seconds. Elapsed time: 0.15 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.12 seconds. CPU system time: 0 seconds. Elapsed time: 0.11 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'linear_ap_fixed_16_6_5_3_0_ap_fixed_16_6_0_0_0_linear_config9_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'linear<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 0, 0, 0>, linear_config9>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 1, function 'linear<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 0, 0, 0>, linear_config9>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.22 seconds. CPU system time: 0 seconds. Elapsed time: 0.25 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.01 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.01 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'linear_ap_fixed_16_6_0_0_0_ap_fixed_16_7_0_0_0_linear_config10_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'linear<ap_fixed<16, 6, 0, 0, 0>, ap_fixed<16, 7, 0, 0, 0>, linear_config10>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 1, function 'linear<ap_fixed<16, 6, 0, 0, 0>, ap_fixed<16, 7, 0, 0, 0>, linear_config10>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.04 seconds. CPU system time: 0 seconds. Elapsed time: 0.03 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.03 seconds. CPU system time: 0 seconds. Elapsed time: 0.03 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_latency_ap_fixed_16_7_0_0_0_ap_fixed_16_6_5_3_0_config11_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'dense_latency<ap_fixed<16, 7, 0, 0, 0>, ap_fixed<16, 6, 5, 3, 0>, config11>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 3, Depth = 3, function 'dense_latency<ap_fixed<16, 7, 0, 0, 0>, ap_fixed<16, 6, 5, 3, 0>, config11>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.08 seconds. CPU system time: 0 seconds. Elapsed time: 0.08 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.04 seconds. CPU system time: 0 seconds. Elapsed time: 0.06 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'linear_ap_fixed_16_6_5_3_0_ap_fixed_16_6_0_0_0_linear_config12_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'linear<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 0, 0, 0>, linear_config12>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 1, function 'linear<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 0, 0, 0>, linear_config12>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.08 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.12 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.01 seconds. CPU system time: 0 seconds. Elapsed time: 0.02 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'sigmoid_ap_fixed_16_6_0_0_0_ap_fixed_16_6_0_0_0_sigmoid_config13_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'sigmoid<ap_fixed<16, 6, 0, 0, 0>, ap_fixed<16, 6, 0, 0, 0>, sigmoid_config13>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 4, function 'sigmoid<ap_fixed<16, 6, 0, 0, 0>, ap_fixed<16, 6, 0, 0, 0>, sigmoid_config13>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.04 seconds. CPU system time: 0 seconds. Elapsed time: 0.04 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.04 seconds. CPU system time: 0 seconds. Elapsed time: 0.04 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'myproject' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'myproject'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 8, Depth = 26, function 'myproject'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.1 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.11 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 1.58 seconds. CPU system time: 0 seconds. Elapsed time: 1.58 seconds; current allocated memory: 935.590 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_latency_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-104] Estimated max fanout for 'dense_latency_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config2_s' is 12105 from HDL expression: (1'b1 == ap_CS_fsm_state1)\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_latency_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config2_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 8.22 seconds. CPU system time: 0.02 seconds. Elapsed time: 8.25 seconds; current allocated memory: 998.906 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'linear_ap_fixed_16_6_5_3_0_ap_fixed_16_6_0_0_0_linear_config3_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_ap_fixed_16_6_5_3_0_ap_fixed_16_6_0_0_0_linear_config3_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 14.93 seconds. CPU system time: 0.22 seconds. Elapsed time: 15.22 seconds; current allocated memory: 1.080 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'linear_ap_fixed_16_6_0_0_0_ap_fixed_16_7_0_0_0_linear_config4_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_ap_fixed_16_6_0_0_0_ap_fixed_16_7_0_0_0_linear_config4_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.05 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.06 seconds; current allocated memory: 1.094 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_latency_ap_fixed_16_7_0_0_0_ap_fixed_16_6_5_3_0_config5_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_5s_19_2_1': 2 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_6s_19_2_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_latency_ap_fixed_16_7_0_0_0_ap_fixed_16_6_5_3_0_config5_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.11 seconds. CPU system time: 0 seconds. Elapsed time: 0.16 seconds; current allocated memory: 1.095 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'linear_ap_fixed_16_6_5_3_0_ap_fixed_16_6_0_0_0_linear_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_ap_fixed_16_6_5_3_0_ap_fixed_16_6_0_0_0_linear_config6_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.27 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.29 seconds; current allocated memory: 1.096 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'linear_ap_fixed_16_6_0_0_0_ap_fixed_16_7_0_0_0_linear_config7_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_ap_fixed_16_6_0_0_0_ap_fixed_16_7_0_0_0_linear_config7_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.05 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.04 seconds; current allocated memory: 1.099 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_latency_ap_fixed_16_7_0_0_0_ap_fixed_16_6_5_3_0_config8_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_5ns_19_2_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_5s_19_2_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_latency_ap_fixed_16_7_0_0_0_ap_fixed_16_6_5_3_0_config8_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.13 seconds. CPU system time: 0 seconds. Elapsed time: 0.17 seconds; current allocated memory: 1.099 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'linear_ap_fixed_16_6_5_3_0_ap_fixed_16_6_0_0_0_linear_config9_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_ap_fixed_16_6_5_3_0_ap_fixed_16_6_0_0_0_linear_config9_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.52 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.53 seconds; current allocated memory: 1.102 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'linear_ap_fixed_16_6_0_0_0_ap_fixed_16_7_0_0_0_linear_config10_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_ap_fixed_16_6_0_0_0_ap_fixed_16_7_0_0_0_linear_config10_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.05 seconds. CPU system time: 0 seconds. Elapsed time: 0.05 seconds; current allocated memory: 1.106 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_latency_ap_fixed_16_7_0_0_0_ap_fixed_16_6_5_3_0_config11_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_latency_ap_fixed_16_7_0_0_0_ap_fixed_16_6_5_3_0_config11_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.13 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.16 seconds; current allocated memory: 1.107 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'linear_ap_fixed_16_6_5_3_0_ap_fixed_16_6_0_0_0_linear_config12_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_ap_fixed_16_6_5_3_0_ap_fixed_16_6_0_0_0_linear_config12_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.2 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.23 seconds; current allocated memory: 1.109 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'sigmoid_ap_fixed_16_6_0_0_0_ap_fixed_16_6_0_0_0_sigmoid_config13_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SYN 201-210] Renamed object name 'sigmoid_ap_fixed_16_6_0_0_0_ap_fixed_16_6_0_0_0_sigmoid_config13_s_sigmoid_table_ROM_AUTO_1R' to 'sigmoid_ap_fixed_16_6_0_0_0_ap_fixed_16_6_0_0_0_sigmoid_config13_s_sigmoid_tabkb' due to the length limit 80\n",
      "INFO: [HLS 200-1030] Apply Unified Pipeline Control on module 'sigmoid_ap_fixed_16_6_0_0_0_ap_fixed_16_6_0_0_0_sigmoid_config13_s' pipeline 'sigmoid<ap_fixed<16, 6, 0, 0, 0>, ap_fixed<16, 6, 0, 0, 0>, sigmoid_config13>' pipeline type 'function pipeline'\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'sigmoid_ap_fixed_16_6_0_0_0_ap_fixed_16_6_0_0_0_sigmoid_config13_s'.\n",
      "INFO: [RTMG 210-279] Implementing memory 'myproject_sigmoid_ap_fixed_16_6_0_0_0_ap_fixed_16_6_0_0_0_sigmoid_config13_s_sigmoid_tabkb' using auto ROMs.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.06 seconds. CPU system time: 0 seconds. Elapsed time: 0.06 seconds; current allocated memory: 1.111 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'myproject' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/fc1_input_input' to 'ap_vld'.\n",
      "INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer13_out_0' to 'ap_vld'.\n",
      "INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer13_out_1' to 'ap_vld'.\n",
      "INFO: [RTGEN 206-500] Setting interface mode on function 'myproject' to 'ap_ctrl_hs'.\n",
      "INFO: [HLS 200-1030] Apply Unified Pipeline Control on module 'myproject' pipeline 'myproject' pipeline type 'function pipeline'\n",
      "INFO: [RTGEN 206-104] Estimated max fanout for 'myproject' is 12562 from HDL expression: ap_rst\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'myproject'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.22 seconds. CPU system time: 0 seconds. Elapsed time: 0.25 seconds; current allocated memory: 1.111 GB.\n",
      "INFO: [HLS 200-111] Finished Generating all RTL models: CPU user time: 7.81 seconds. CPU system time: 0.01 seconds. Elapsed time: 7.82 seconds; current allocated memory: 1.116 GB.\n",
      "INFO: [HLS 200-111] Finished Updating report files: CPU user time: 0.81 seconds. CPU system time: 0.02 seconds. Elapsed time: 0.84 seconds; current allocated memory: 1.133 GB.\n",
      "INFO: [VHDL 208-304] Generating VHDL RTL for myproject.\n",
      "INFO: [VLOG 209-307] Generating Verilog RTL for myproject.\n",
      "INFO: [HLS 200-789] **** Estimated Fmax: 230.83 MHz\n",
      "INFO: [HLS 200-111] Finished Command csynth_design CPU user time: 382.53 seconds. CPU system time: 2.28 seconds. Elapsed time: 385.75 seconds; current allocated memory: 900.586 MB.\n",
      "***** C/RTL SYNTHESIS COMPLETED IN 0h6m35s *****\n",
      "INFO: [HLS 200-112] Total CPU user time: 384.37 seconds. Total CPU system time: 2.47 seconds. Total elapsed time: 397.7 seconds; peak allocated memory: 1.133 GB.\n",
      "INFO: [Common 17-206] Exiting vitis_hls at Tue Mar 25 11:07:10 2025...\n",
      "Vivado synthesis report not found.\n",
      "Cosim report not found.\n",
      "Timing report not found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'CSynthesisReport': {'TargetClockPeriod': '5.00',\n",
       "  'EstimatedClockPeriod': '4.332',\n",
       "  'BestLatency': '25',\n",
       "  'WorstLatency': '25',\n",
       "  'IntervalMin': '8',\n",
       "  'IntervalMax': '8',\n",
       "  'BRAM_18K': '1',\n",
       "  'DSP': '5',\n",
       "  'FF': '35287',\n",
       "  'LUT': '51913',\n",
       "  'URAM': '0',\n",
       "  'AvailableBRAM_18K': '280',\n",
       "  'AvailableDSP': '220',\n",
       "  'AvailableFF': '106400',\n",
       "  'AvailableLUT': '53200',\n",
       "  'AvailableURAM': '0'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hls_model.build(csim=False, export=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Valencia, Spain - 2025\n",
    "\n",
    "Romina Soledad Molina, Ph.D. - MLab/STI ICTP, Trieste, Italy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
